{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4285d516-6849-4a09-b1e4-75ada05e5408",
   "metadata": {},
   "source": [
    "# Inference and Trajectory Forecasting with TrajCast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c4f48-3683-4443-a35b-a27d7d901507",
   "metadata": {},
   "source": [
    "This notebook provides a short guide on how to deploy a *TrajCast* model. Here, we will focus on single forward passeses as well as performing a roll-out to forecast a trajectory for paracetamol. \n",
    "\n",
    "\n",
    "This tutorial covers: \n",
    "- Loading a previously trained model.\n",
    "- Single-step prediction for validation based on small test set.\n",
    "- Performing roll-out to forecast a short trajectory for paracetmol.\n",
    "\n",
    "> **_Note_:** \n",
    "> This notebook won't cover model training. For details on how to train *TrajCast* please refer to this [example notebook](../training/training.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "> **_Note_:** \n",
    "> This code is still under development. This notebook is intended to provide help and guidance in getting started. Future updates will focus on making the code more efficient and user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0cc53-e12e-406f-a630-cdaa13f998fb",
   "metadata": {},
   "source": [
    "# Loading a Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2b913-c7c5-4e0b-b747-f142452631e9",
   "metadata": {},
   "source": [
    "We start by downloading the model weights from HuggingFace. Here, we use the model reported in our manuscript for paracetamol with a prediction horizon of 7 fs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c6928-c382-435e-8d6e-0b6761a6c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "for file in [\"state_dict_e3nn.pt\", \"config_e3nn.yaml\"]:\n",
    "    hf_hub_download(\n",
    "        repo_id=\"ibm-research/trajcast.models-arxiv2025\",\n",
    "        revision=\"main\",\n",
    "        filename=f\"paracetamol/{file}\",\n",
    "        local_dir=\"./\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90599c55-8473-4b8f-84ea-2bbce53af9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fe92c-f967-4cb9-9604-26ca16014f28",
   "metadata": {},
   "source": [
    "As all models in our work were trained using double precision, we set this as default type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bb2a2-4e31-444f-9701-6fdf57a3278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32983c9b-6339-466a-a2f1-dc8c2e3bbeb0",
   "metadata": {},
   "source": [
    "With weights and configuration YAML file at hand, we can load and instantiate our model.\n",
    "\n",
    "> **_Note_:** \n",
    "> Choose the state dictionary dependent on whether you have CUDA and cuEquivariance installed. For transferabilitiy, here we use the e3nn dictionary to allow running on a CPU. In general, to convert configuration YAMLs and state dictionaries from one O3 backend to the other, please use [this script](../../trajcast/cli/convert_o3_backend.py). Be aware, however, that dependent on the device where a model with cueq backend is initialized, some parameter names might vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6a396-9d10-4a92-b115-aa03aba651a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajcast.model.models import EfficientTrajCastModel\n",
    "\n",
    "# initialize model\n",
    "model = EfficientTrajCastModel.build_from_yaml(\"paracetamol/config_e3nn.yaml\")\n",
    "\n",
    "# # load state dictionary\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"paracetamol/state_dict_e3nn.pt\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fa09a-73d3-4b0d-9c9f-84565fe20bd2",
   "metadata": {},
   "source": [
    "# Single-step Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c93d1-28d7-478d-ae2e-f22587d611f2",
   "metadata": {},
   "source": [
    "Once we have our model, let's use it to validate it's performance on a hold out test set. Here, we use a 10% subset of the test set for which we reported errors in our original manuscript.\n",
    "\n",
    "If not done so already, we start by downloading the dataset from HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee360b-dfe6-4530-817a-e2f05ba160eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"test\"]:\n",
    "    hf_hub_download(\n",
    "        repo_id=\"ibm-research/trajcast.datasets-arxiv2025\",\n",
    "        repo_type=\"dataset\",\n",
    "        revision=\"main\",\n",
    "        filename=f\"example/{dataset}.extxyz\",\n",
    "        local_dir=\"../data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f116c-a779-43c2-b622-a4a48639585e",
   "metadata": {},
   "source": [
    "Next, we load it using our `AtomicGraphDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108091b-6b8c-40dd-8d99-71ac8f4f4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajcast.data.dataset import AtomicGraphDataset\n",
    "\n",
    "test_set_dict = {\n",
    "    \"root\": \".\",  # Directory where the data lies\n",
    "    \"name\": \"paracetamol_test\",  # Name the processed dataset should have\n",
    "    \"cutoff_radius\": 4.0,  # Cutoff for defining edges between nodes, should be the same as for model, will be fixed later\n",
    "    \"files\": [\n",
    "        \"../data/example/test.extxyz\"\n",
    "    ],  # Files with the data, can be multiple ones\n",
    "    \"rename\": True,  # Dependent on the precision it will add a tag to the processed filename\n",
    "    \"atom_type_mapper\": {  # Mapping chemical atom types to variables within the model, not necessary but less error prone\n",
    "        1: 0,  # H -> 0\n",
    "        6: 1,  # C -> 1\n",
    "        7: 2,  # N -> 2\n",
    "        8: 3,  # O -> 3\n",
    "    },\n",
    "}\n",
    "\n",
    "test_set = AtomicGraphDataset(**test_set_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd23e5-9a42-405f-9453-73f16a1e99bd",
   "metadata": {},
   "source": [
    "Now we can pass configurations to our model and perform a forward pass to predict the displacement vectors and new velocities. However, as the current implementation of *TrajCast* returns these quantaties normalized by the RMS of these vectors observed in the training set. The scaling constants are easily accessible via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ec8ea-e03d-47cd-aec8-1f745cd4a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_scale = model._encoding.Normalization.stds[\"update_velocities\"].item()\n",
    "disp_scale = model._encoding.Normalization.stds[\"displacements\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f35325-400e-4a7d-96a4-9b1240e50234",
   "metadata": {},
   "source": [
    "We then can create a dataloader and loop over our test set. As can be seen from the config.yaml files, the normalized predicted outputs are stored in a field called `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8a820-24dd-4c44-ac2b-d2b9360ba51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "data_loader = DataLoader(test_set, batch_size=5, shuffle=False)\n",
    "\n",
    "# get true displacements and update velociites\n",
    "true_vel = test_set.update_velocities.detach().numpy()\n",
    "true_disp = test_set.displacements.detach().numpy()\n",
    "\n",
    "model.eval()\n",
    "pred_vel = []\n",
    "pred_disp = []\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        # forward pass\n",
    "        batch = model(batch.to(device))\n",
    "\n",
    "        # save predicted displacements and velocities\n",
    "        pred_disp.append(batch.target[:, 0:3].cpu().numpy() * disp_scale)\n",
    "        pred_vel.append(batch.target[:, 3:].cpu().numpy() * vel_scale)\n",
    "\n",
    "pred_disp = np.concatenate(pred_disp)\n",
    "pred_vel = np.concatenate(pred_vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519453e-19f6-4680-a1f7-90aa6172c106",
   "metadata": {},
   "source": [
    "To visually inspect the accuracy of our model, we create a parity plot for the displacements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c1d2d-4c6e-4c56-8fcb-d05341cf87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.scatter(true_disp, pred_disp, s=3)\n",
    "ax.plot([-0.4, 0.4], [-0.4, 0.4], color=\"k\", ls=\"--\", lw=1)\n",
    "\n",
    "ax.set_xlim(-0.35, 0.35)\n",
    "ax.set_ylim(-0.35, 0.35)\n",
    "ax.set_ylabel(r\"Predicted Displacements $[\\mathrm{\\AA}]$\")\n",
    "ax.set_xlabel(r\"Reference Displacements $[\\mathrm{\\AA}]$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e399ac-83b6-4141-a26a-5528f8e50ac9",
   "metadata": {},
   "source": [
    "Assuming we are happy with this overall performance, we can now move to rolling out our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9d4f4-3d8b-4477-9aa6-fbb7c3d55c3c",
   "metadata": {},
   "source": [
    "# Roll-out and Trajectory Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818607d-35bc-4262-8bc0-128c0181747d",
   "metadata": {},
   "source": [
    "Similar to setting up traditional MD simulations, we start by defining our initial configuration. For the sake of simplicity, here we simply take one configuratino of the example test but remove the reference labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f4731-4c47-44d3-958c-4540c1a94b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase.io\n",
    "\n",
    "start_frame = ase.io.read(\n",
    "    \"/Users/fabianthiemann/Projects/01_TrajCast/paper/data/oss/example/test.extxyz\",\n",
    "    index=\"-1\",\n",
    ")\n",
    "start_frame.center()\n",
    "_ = start_frame.arrays.pop(\"displacements\")\n",
    "_ = start_frame.arrays.pop(\"update_velocities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de69b3d-ede7-479e-922a-9ba1629de9a3",
   "metadata": {},
   "source": [
    "Apart from the initial structure, we need to define a few settings in a forecasting protocol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e1a62-dea3-44a2-b71b-f7e7b7caa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = {\n",
    "    \"units\": \"real\",  # Units, in which the trajectory forecasting is performed. Here we use the same convention as lammps: https://docs.lammps.org/units.html\n",
    "    \"run\": 100,  # Number of steps to be performed\n",
    "    \"temperature\": 300,  # Target temperature\n",
    "    \"extra_dof\": 6,  # Number of degrees of freedom to be subtracted from 3N for temperature definition.\n",
    "    \"timestep\": 7.0,  # Prediction horizon the model has been trained on\n",
    "    \"configuration\": start_frame,  # Initial configuration\n",
    "    \"model_type\": \"EfficientTrajCastModel\",  # Type of model to be used\n",
    "    \"model\": model,  # Which model to use\n",
    "    \"thermostat\": {\n",
    "        \"Tdamp\": 70.0\n",
    "    },  # Arguments for the thermostat, if no thermostat is specified, forecast will be in NVE ensemble\n",
    "    \"velocities\": {  # Whether to assign initial velocities (otherwise read from start_frame)\n",
    "        \"Temperature\": 300,  # Velocities will correspond to this temperature\n",
    "        \"linear\": True,  # Whether assigned velocities should be free of total linear momentum\n",
    "        \"angular\": True,  # Whether assigned velocities should be free of total angular momentum\n",
    "        \"distribution\": \"gaussian\",  # Distribution from which velocities are drawn (uniform or Gaussian)\n",
    "    },\n",
    "    \"write\": {  # Details on how often and where to save frames\n",
    "        \"filename\": \"./example_traj.extxyz\",  # Path to the output file\n",
    "        \"every\": 1,  # Save every Nth frame\n",
    "    },\n",
    "    \"device\": device,  # Device the forecasting will be run on\n",
    "    \"seed\": 42,  # Seed for thermostat and initial velocities (if applicable)\n",
    "    \"set_momenta\": {  # Directionary with target linear and/or angular momentum\n",
    "        \"linear\": torch.zeros(3, device=device),\n",
    "        \"angular\": torch.tensor([], device=device),\n",
    "    },\n",
    "    \"zero_momentum\": {  # Settings to zero the total linear and angular momentum induced by the thermostat\n",
    "        \"every\": 100,  # Remove total net momenta every N steps\n",
    "        \"linear\": False,  # Whether to remove linear momentum (should not be necessary if initiliazed with zero)\n",
    "        \"angular\": True,  # Whether to remove angular momentum\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fe43f-1c7a-4f43-9150-b4b70595c426",
   "metadata": {},
   "source": [
    "Once we defined how we would like to perform our forecasting, we can simply pass the protocol to the `Forecast` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2473db-86db-4f99-9b3f-02848016146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajcast.model.forecast import Forecast\n",
    "\n",
    "forecaster = Forecast(protocol=protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96b1ed-e72f-44b8-afe2-76e98334ac2a",
   "metadata": {},
   "source": [
    "Now we can simply generate our trajectory by calling `generate_trajectory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e323dae-d562-4624-899c-d9dd2a09180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.generate_trajectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12137bdc-7302-4648-8433-1c9f08aa31ef",
   "metadata": {},
   "source": [
    "If everything went well, we should be able to visualize this trajectory here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94132f8f-7fd4-4252-b378-bf4ddc817d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nglview\n",
    "\n",
    "generated_traj = ase.io.read(\"example_traj.extxyz\", index=\":\")\n",
    "nglview.show_asetraj(generated_traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
